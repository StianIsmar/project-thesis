{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScorer():\n",
    "\t'''\n",
    "\tUse this class to encapsulate and/or aggregate multiple scoring functions so that it can be passed as an argument for scoring in scikit's cross_val_score function.\n",
    "\tInstances of this class are also callables, with signature as needed by `cross_val_score`.\n",
    "\t'''\n",
    "\n",
    "\tdef __init__(self, metrics):\n",
    "\t\t'''\n",
    "\t\tCreate a new instance of MultiScorer.\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tmetrics: dict\n",
    "\t\t\tThe metrics to be used by the scorer.\n",
    "\t\t\tThe dictionary must have as key a name (str) for the metric and as value a tuple containing the metric function itself and a dict literal of the additional named arguments to be passed to the function.\n",
    "\t\t\tThe metric function should be one of the `sklearn.metrics` function or any other callable with the same signature: `metric(y_real, y, **kwargs)`.\n",
    "\t\t'''\n",
    "\n",
    "\t\tself.metrics = metrics\n",
    "\t\tself.results = {}\n",
    "\t\tself._called = False\n",
    "\t\tself.n_folds = 0\n",
    "\n",
    "\t\tfor metric in metrics.keys():\n",
    "\t\t\tself.results[metric] = []\n",
    "\n",
    "\n",
    "\n",
    "\tdef __call__(self, estimator, X, y):\n",
    "\t\t'''\n",
    "\t\tTo be called by for evaluation from sklearn's GridSearchCV or cross_val_score.\n",
    "\t\tParameters are as they are defined in the respective documentation.\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\t\tA dummy value of 0.5 just for compatibility reasons.\n",
    "\t\t'''\n",
    "\n",
    "\t\tself.n_folds += 1\n",
    "\t\tyPred = estimator.predict(X)\n",
    "\n",
    "\t\tfor key in self.metrics.keys():\n",
    "\t\t\tmetric, kwargs = self.metrics[key]\n",
    "\n",
    "\t\t\tself.results[key].append(metric(y, yPred, **kwargs))\n",
    "\n",
    "\t\tself._called = True\n",
    "\n",
    "\t\treturn 0.5\n",
    "\n",
    "\tdef get_metric_names(self):\n",
    "\t\t'''\n",
    "\t\tGet all the metric names as given when initialized\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tA list containing the given names (str) of the metrics\n",
    "\t\t'''\n",
    "\n",
    "\t\treturn self.metrics.keys()\n",
    "\n",
    "\tdef get_results(self, metric=None, fold='all'):\n",
    "\t\t'''\n",
    "\t\tGet the results of a specific or all the metrics.\n",
    "\t\tThis method should be called after the object itself has been called so that the metrics are applied.\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tmetric: str or None (default)\n",
    "\t\t\tThe given name of a metric to return its result(s). If omitted the results of all metrics will be returned.\n",
    "\t\tfold: int in range [1, number_of_folds] or 'all' (Default)\n",
    "\t\t \tGet the metric(s) results for the specific fold.\n",
    "\t\t\tThe number of folds corresponds to the number of times the instance is called.\n",
    "\t\t\tIf its value is a number, either the score of a single metric for that fold or a dictionary of the (single) scores for that fold will be returned, depending on the value of `metric` parameter.\n",
    "\t\t\tIf its value is 'all', either a list of a single metric or a dictionary containing the lists of scores for all folds will be returned, depending on the value of `metric` parameter.\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tmetric_result_for_one_fold\n",
    "\t\t\tThe result of the designated metric function for the specific fold, if `metric` parameter was not omitted and an integer value was given to `fold` parameter.\n",
    "\t\t\tIf  the value of `metric` does not correspond to a metric name, `None` will be returned.\n",
    "\t\tall_metric_results_for_one_fold: dict\n",
    "\t\t\tA dict having as keys the names of the metrics and as values their results for the specific fold.\n",
    "\t\t\tThis will be returned only if `metric` parameter was omitted and an integer value was given to `fold` parameter.\n",
    "\t\tmetric_results_for_all_folds: list\n",
    "\t\t\tA list of length number_of_folds containing the results of all folds for the specific metric, if `metric` parameter was not omitted and value 'all' was given to `fold`.\n",
    "\t\t\tIf  the value of `metric` does not correspond to a metric name, `None` will be returned.\n",
    "\t\tall_metric_results_for_all_folds: dict of lists\n",
    "\t\t\tA dict having as keys the names of the metrics and as values lists (of length number_of_folds) of their results for all folds.\n",
    "\t\t\tThis will be returned only if `metric` parameter was omitted and 'all' value was given to `fold` parameter.\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tUserWarning\n",
    "\t\t\tIf this method is called before the instance is called for evaluation.\n",
    "\t\tValueError\n",
    "\t\t\tIf the value for `fold` parameter is not appropriate.\n",
    "\t\t'''\n",
    "\n",
    "\t\tif not self._called:\n",
    "\t\t\traise UserWarning('Evaluation has not been performed yet.')\n",
    "\n",
    "\n",
    "\t\tif isinstance(fold, str) and fold == 'all':\n",
    "\n",
    "\t\t\tif metric is None:\n",
    "\t\t\t\treturn self.results\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn self.results[metric]\n",
    "\n",
    "\t\telif isinstance(fold, int):\n",
    "\n",
    "\t\t\tif fold not in range(1, self.n_folds+1): raise ValueError('Invalid fold index: '+str(fold))\n",
    "\n",
    "\t\t\tif metric is None:\n",
    "\t\t\t\tres = dict()\n",
    "\n",
    "\t\t\t\tfor key in self.results.keys():\n",
    "\t\t\t\t\tres[key] = self.results[key][fold-1]\n",
    "\n",
    "\t\t\t\treturn res\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn self.results[metric][fold-1]\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('Unexpected fold value: %s' %(str(fold)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
