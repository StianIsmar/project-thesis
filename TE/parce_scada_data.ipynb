{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import nbimporter\n",
    "\n",
    "import fill_in_blanks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =2 \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_to_dfs = []\n",
    "directory = \"./scada_data/30okt\"\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        full_path = os.path.join(directory, filename)\n",
    "        print(full_path)\n",
    "        df = pd.read_csv(os.path.join(directory, filename),sep=\";\")\n",
    "        all_csv_to_dfs.append(df)\n",
    "\n",
    "        continue \n",
    "    else: \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_csv_to_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in all_csv_to_dfs:\n",
    "    print(df.TimeStamp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure all dataframes have the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show one dataframe\n",
    "# Splitting dataframes from date: 25-09-2017 13:20:00\n",
    "\n",
    "all_csv_to_dfs = fill_in_blanks.slice_df(all_csv_to_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Cutting away rows after date: \"20-10-2019 13:20:00\"\n",
    "# All dataframes should now have the same shape[1].\n",
    "i = 0\n",
    "for dataframe in all_csv_to_dfs:\n",
    "\n",
    "    location = np.where(dataframe[\"TimeStamp\"].str.contains(\"20-10-2019 13:20:00\"))\n",
    "    print(location)\n",
    "    split_on_index = location[0][0]\n",
    "    print(split_on_index)\n",
    "\n",
    "    # Splitting\n",
    "    df1 = dataframe.iloc[:split_on_index, :]\n",
    "    df2 = dataframe.iloc[split_on_index:, :]\n",
    "\n",
    "    # Reseting index\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    all_csv_to_dfs[i] = df1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_to_dfs[0].iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a csv contains more than one:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "# Function returns a list of dfs for each datafram\n",
    "def parce_csv_with_multiple_wt(df):\n",
    "\n",
    "  scada_dfs1 = []\n",
    "  for i in range(0,25):\n",
    "      if (i < 9):\n",
    "          wt = (\"BESS-WTG0{0}\".format(i+1))\n",
    "      else:\n",
    "          wt = (\"BESS-WTG{0}\".format(i+1))\n",
    "\n",
    "      ''' \n",
    "       Check which column names contain the string wt.\n",
    "       Fro example, BESS-WT02XXXXX, is a paramenter for turbine 02\n",
    "       and is filtered into a seperate dataframe:\n",
    "      '''\n",
    "      # Take out the TimeStamp column, since it is being filtered away:\n",
    "      time_stamp_column = df.iloc[:,0]\n",
    "\n",
    "      filtered = df[df.columns[df.columns.to_series().str.contains(wt)]]\n",
    "      filtered.insert(loc=0, column='TimeStamp', value=time_stamp_column)\n",
    "\n",
    "      # Add it to the return list\n",
    "      if (filtered.shape[1] > 0):\n",
    "        print(\"FILTERED\", filtered.shape)\n",
    "\n",
    "        scada_dfs1.append(filtered)\n",
    "        print(\"Appended...\")\n",
    "  del df\n",
    "  gc.collect()\n",
    "    \n",
    "  return scada_dfs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished_list = []\n",
    "for dataframe in all_csv_to_dfs:\n",
    "  more_than_one = (dataframe.shape[1] > 35)\n",
    "\n",
    "  if (more_than_one):\n",
    "    print(\"more_than_one\", more_than_one)\n",
    "    \n",
    "    # Split it into more\n",
    "    parced_list = parce_csv_with_multiple_wt(dataframe)\n",
    "    \n",
    "    for parced in parced_list:\n",
    "      print(\"parced.shape[1]: \", parced.shape[1])\n",
    "      if (parced.shape[1] == 35):\n",
    "        finished_list.append(parced)\n",
    "  else:\n",
    "    # just add it to the list if it has all the features we need\n",
    "    if (dataframe.shape[1] == 35):\n",
    "      finished_list.append(dataframe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(finished_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new array with unique dataframes\n",
    "\n",
    "def check_in_in_list(df,list1):\n",
    "    boolean = \"false\"\n",
    "    for l in list1:\n",
    "        if(df.columns.equals(l.columns)):\n",
    "            boolean = \"true\"\n",
    "    return boolean\n",
    "            \n",
    "\n",
    "def unique(list1): \n",
    "  \n",
    "    # intilize a null list \n",
    "    unique_list = [] \n",
    "      \n",
    "    # traverse for all elements \n",
    "    for x in list1: \n",
    "        # check if exists in unique_list or not \n",
    "        if (check_in_in_list(x,unique_list) == \"false\"):\n",
    "            unique_list.append(x) \n",
    "    return unique_list\n",
    "\n",
    "unique_finished = unique(finished_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The unique dataframes:\n",
    "\n",
    "print(len(unique_finished))\n",
    "# for u in unique_finished:\n",
    "unique_finished[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the dataframes to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#path = \"./DataFromBazefield/scada_data_bessaker/\"\n",
    "path = '/Volumes/Uten navn/scada_data_bessaker/'\n",
    "# Sorting so that we have df from 01 -> 24.\n",
    "sorted_list = sorted(unique_finished, key=lambda x: x.columns[1].split(\"-\")[1], reverse=False)\n",
    "\n",
    "\n",
    "for dataframe in sorted_list:\n",
    "    windturbine_id = dataframe.columns[1].split(\"-\")[1]\n",
    "    print(windturbine_id)\n",
    "    \n",
    "    # SAVE IT: Uncomment\n",
    "    dataframe.to_csv(path + windturbine_id + \".gz\", compression='gzip')\n",
    "\n",
    "    #dataframe.to_pickle(path + windturbine_id + \".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can actually call the functions in fill_in_blanks here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
