{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6inTwDO4WXF8"
   },
   "source": [
    "# Filling in blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i2LX8RZHWtZF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "del \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 12\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsu-FUxMXVGV"
   },
   "outputs": [],
   "source": [
    "def count(dataframe):\n",
    "    print(np.logical_not(dataframe.isnull()).sum()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SCADA operational data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_SCADA_data_from_all_turbines(dir_path):\n",
    "    allFiles = glob.glob(dir_path + \"/*.csv\")\n",
    "\n",
    "    list_of_wt_scada_data = []\n",
    "    count = 1\n",
    "    for file in allFiles:\n",
    "        turbine_data = pd.read_csv(file, sep = ',', index_col=0)\n",
    "        list_of_wt_scada_data.append(turbine_data)\n",
    "        print('Loaded File: {}'.format(count))\n",
    "        count += 1\n",
    "    print('Loaded All Files.')\n",
    "    return list_of_wt_scada_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded File: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/arraysetops.py:571: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded File: 2\n",
      "Loaded File: 3\n",
      "Loaded File: 4\n",
      "Loaded File: 5\n",
      "Loaded File: 6\n",
      "Loaded File: 7\n",
      "Loaded File: 8\n",
      "Loaded File: 9\n",
      "Loaded File: 10\n",
      "Loaded File: 11\n",
      "Loaded File: 12\n",
      "Loaded File: 13\n",
      "Loaded File: 14\n",
      "Loaded File: 15\n",
      "Loaded File: 16\n",
      "Loaded File: 17\n",
      "Loaded File: 18\n",
      "Loaded File: 19\n",
      "Loaded File: 20\n",
      "Loaded File: 21\n",
      "Loaded File: 22\n",
      "Loaded File: 23\n",
      "Loaded File: 24\n",
      "Loaded File: 25\n",
      "Loaded All Files.\n"
     ]
    }
   ],
   "source": [
    "dir_path = './DataFromBazefield/scada_data_bessaker/'\n",
    "list_of_wt_scada_data = load_SCADA_data_from_all_turbines(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeStamp;BESS-WTG01-WindVane (Average);BESS-WTG01-WindSpeed (Average);BESS-WTG01-RotorSpeed (Average);BESS-WTG01-NacelleDirection (Average);BESS-WTG01-ActivePower (Average);BESS-WTG01-Spinner-Temperature (Average);BESS-WTG01-Log-T-Raw-FrontBearingTemperature (Average);BESS-WTG01-Log-T-Raw-RearBearingTemperature (Average);BESS-WTG01-Log-T-Raw-BladeAPitchHeatSink (Average);BESS-WTG01-Log-T-Raw-BladeBPitchHeatSink (Average);BESS-WTG01-Log-T-Raw-BladeCPitchHeatSink (Average);BESS-WTG01-Log-T-Raw-BladeAPitchControlBox (Average);BESS-WTG01-Log-T-Raw-BladeBPitchControlBox (Average);BESS-WTG01-Log-T-Raw-BladeCPitchControlBox (Average);BESS-WTG01-Log-T-Raw-BladeATemperature (Average);BESS-WTG01-Log-T-Raw-BladeBTemperature (Average);BESS-WTG01-Log-T-Raw-BladeCTemperature (Average);BESS-WTG01-Log-T-Raw-Rotor1Temperature (Average);BESS-WTG01-Log-T-Raw-Rotor2Temperature (Average);BESS-WTG01-Log-T-Raw-Stator2Temperature (Average);BESS-WTG01-Log-T-Raw-Stator1Temperature (Average);BESS-WTG01-Log-T-Raw-NacelleAmbientTemperature (Average);BESS-WTG01-Nacelle-Temperature (Average);BESS-WTG01-Log-T-Raw-NacelleControlCabinetTemperature (Average);BESS-WTG01-Log-T-Raw-Rectifier1HeatSink (Average);BESS-WTG01-Log-T-Raw-Rectifier2HeatSink (Average);BESS-WTG01-Log-T-Raw-RectifierCabinetTemperature (Average);BESS-WTG01-Log-T-Raw-ExcitationHeatSink (Average);BESS-WTG01-Ambient-Temperature (Average);BESS-WTG01-Log-T-Raw-TowerTemperature (Average);BESS-WTG01-Log-T-Raw-ControlCabinetTemperature (Average);BESS-WTG01-Log-T-Raw-TransformerTemperature (Average);BESS-WTG01-Average blade angle across A B C (Average);BESS-WTG01-WindDirection (Average)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:00:00;;4.5;9.75;227;109;24;;;;;;;;;;;;;;;;;23;;;;;;11;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:00:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:01:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:01:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:02:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:02:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:03:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:03:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:04:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:04:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:05:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:05:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:06:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:06:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:07:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:07:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:08:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:08:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:09:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:09:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:10:00;;4.59999990463257;9.89999961853027;225;117;24;;;;;;;;;;;;;;;;;23;;;;;;11;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:10:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:11:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:11:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:12:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:12:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:13:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:13:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:14:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15-07-2017 00:14:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:45:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:45:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:46:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:46:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:47:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:47:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:48:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:48:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:49:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:49:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:50:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:50:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:51:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:51:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:52:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:52:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:53:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:53:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:54:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:54:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:55:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:55:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:56:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:56:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:57:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:57:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:58:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:58:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:59:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16-10-2019 23:59:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2373120 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [15-07-2017 00:00:00;;4.5;9.75;227;109;24;;;;;;;;;;;;;;;;;23;;;;;;11;;;;;, 15-07-2017 00:00:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:01:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:01:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:02:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:02:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:03:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:03:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:04:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:04:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:05:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:05:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:06:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:06:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:07:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:07:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:08:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:08:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:09:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:09:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:10:00;;4.59999990463257;9.89999961853027;225;117;24;;;;;;;;;;;;;;;;;23;;;;;;11;;;;;, 15-07-2017 00:10:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:11:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:11:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:12:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:12:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:13:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:13:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:14:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:14:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:15:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:15:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:16:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:16:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:17:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:17:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:18:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:18:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:19:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:19:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:20:00;;4.69999980926514;9.86999988555908;220;116;24;;;;;;;;;;;;;;;;;23;;;;;;11;;;;;, 15-07-2017 00:20:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:21:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:21:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:22:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:22:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:23:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:23:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:24:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:24:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:25:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:25:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:26:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:26:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:27:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:27:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:28:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:28:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:29:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:29:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:30:00;;4.09999990463257;9.23999977111816;214;88;24;;;;;;;;;;;;;;;;;23;;;;;;11;;;;;, 15-07-2017 00:30:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:31:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:31:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:32:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:32:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:33:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:33:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:34:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:34:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:35:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:35:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:36:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:36:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:37:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:37:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:38:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:38:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:39:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:39:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:40:00;;5;10.6199998855591;223;152;24;;;;;;;;;;;;;;;;;23;;;;;;11;;;;;, 15-07-2017 00:40:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:41:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:41:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:42:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:42:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:43:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:43:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:44:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:44:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:45:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:45:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:46:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:46:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:47:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:47:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:48:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:48:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:49:00;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, 15-07-2017 00:49:30;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;, ...]\n",
       "\n",
       "[2373120 rows x 0 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_wt_scada_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice each dataframe on the data where there is data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "Q6xheQaFbIKC",
    "outputId": "46c39430-e56f-4080-96ad-f28c9f28bb36"
   },
   "outputs": [],
   "source": [
    "# This dataset is a dataset for a SINGLE wind turbine:\n",
    "\n",
    "# Slice dataset on this row nr.: 177228 (4-09-2017 12:54:00)\n",
    "#df.iloc[[177228]]\n",
    "\n",
    "def slice_df(list_of_dataframes):\n",
    "    i = 0\n",
    "    for dataframe in list_of_dataframes:\n",
    "        print(i)\n",
    "        location = np.where(dataframe[\"TimeStamp\"].str.contains(\"25-10-2017 13:20:00\"))\n",
    "        print(location)\n",
    "        split_on_index = location[0][0]\n",
    "        print(split_on_index)\n",
    "\n",
    "        # Splitting\n",
    "        df1 = dataframe.iloc[:split_on_index, :]\n",
    "        df2 = dataframe.iloc[split_on_index:, :]\n",
    "\n",
    "        # Reseting index\n",
    "        df2 = df2.reset_index(drop=True)\n",
    "        list_of_dataframes[i] = df2\n",
    "        i+=1\n",
    "        \n",
    "    return list_of_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_wt_scada_data = slice_df(list_of_wt_scada_data)\n",
    "list_of_wt_scada_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4Zg8smvfX0p"
   },
   "source": [
    "## Find index of first value in a column that is not NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQWfMq7wyP4G"
   },
   "outputs": [],
   "source": [
    "# Find the first non-NaN value in a column\n",
    "def find_first_not_nan(df,column_name):\n",
    "    ser = df[column_name].notnull()\n",
    "    length = ser.shape[0]\n",
    "\n",
    "    for i in range (length):\n",
    "        if (ser[i] == True):\n",
    "            return i\n",
    "    return \"no values in column!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aSKq8VP-fijA"
   },
   "source": [
    "## Loop through all columns in the dataset and put in the first not NaN number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlfIzNUrqxHA"
   },
   "outputs": [],
   "source": [
    "# Looping all columns in dataframe\n",
    "def loop_through_and_fill_first_val(data):\n",
    "    for col in data.columns:\n",
    "        index = find_first_not_nan(data,col)\n",
    "\n",
    "        if (index != 0):\n",
    "          # Put the value at the found index at the first index:\n",
    "            data.at[0, col] = data.at[index, col]\n",
    "        \n",
    "        # Dropping columns if the first value is too far in the data set\n",
    "        # if (index > 200):\n",
    "            # data.drop([col], axis=1,inplace = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_wt_scada_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2x4BEau3Mr4"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for dataframe in list_of_wt_scada_data:\n",
    "    print(i)\n",
    "    dataframe = loop_through_and_fill_first_val(dataframe)\n",
    "    list_of_wt_scada_data[i] = dataframe\n",
    "    i += 1\n",
    "\n",
    "# list_of_wt_scada_data[1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQZ9pUbh33S7"
   },
   "source": [
    "### Filling all missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o56RsspGw6Yb"
   },
   "outputs": [],
   "source": [
    "def fill_missing_values(dataframe):\n",
    "    # Filling in the missing values:\n",
    "    dataframe.fillna(method='ffill', inplace=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzc0Lc0-4eh4"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for dataframe in list_of_wt_scada_data:\n",
    "    print('Filling in dataframe: {}'.format(i))\n",
    "    dataframe = fill_missing_values(dataframe)\n",
    "    list_of_wt_scada_data[i] = dataframe\n",
    "    i += 1\n",
    "for col in list_of_wt_scada_data[0].head().columns:\n",
    "    if (len(col.split('BESS-WTG01-')) > 1):\n",
    "        print((col.split('BESS-WTG01-')[1]).split(\"(Average)\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def remove_microseconds(dt):\n",
    "    return dt.replace(microsecond=0)\n",
    "\n",
    "\n",
    "dataframe['TimeStamp'] = pd.to_datetime(dataframe['TimeStamp'])\n",
    "# dataframe['TimeStamp'] = dataframe['TimeStamp'].apply(lambda x: remove_microseconds(x)) \n",
    "\n",
    "\n",
    "# dataframe['TimeStamp'] = pd.to_datetime(dataframe['TimeStamp'], format='%Y-%m-%d %H:%M:%S').dt.strftime('%d-%m-%Y %H:%M:%S.%F')\n",
    "dataframe\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def remove_microseconds(dt):\n",
    "    return dt.replace(microsecond=0)\n",
    "\n",
    "for dataframe in list_of_wt_scada_data:\n",
    "    dataframe['TimeStamp'] = pd.to_datetime(dataframe['TimeStamp'])\n",
    "    # dataframe['TimeStamp'] = dataframe['TimeStamp'].apply(lambda x: remove_microseconds(x)) \n",
    "\n",
    "\n",
    "# dataframe['TimeStamp'] = pd.to_datetime(dataframe['TimeStamp'], format='%Y-%m-%d %H:%M:%S').dt.strftime('%d-%m-%Y %H:%M:%S.%F')\n",
    "dataframe\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24XvDwfIZc-x"
   },
   "source": [
    "# The Error log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_yTx45waYat"
   },
   "source": [
    "### Reading the data for WT01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "tvc6Z2bt9aHb"
   },
   "outputs": [],
   "source": [
    "df_log = pd.read_excel('./DataFromBazefield/AlarmlogBessaker.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the error log into each WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_errors_on_wt(error_log):\n",
    "    individual_turbine_alarm = {}\n",
    "    for i in range(25):\n",
    "        if(i+1 < 10):\n",
    "            individual_turbine_alarm[i+1] = error_log.loc[error_log['Turbine'] == 'BESS-WTG0{0}'.format(i+1)]\n",
    "        else :\n",
    "            individual_turbine_alarm[i+1] = error_log.loc[error_log['Turbine'] == 'BESS-WTG{0}'.format(i+1)]\n",
    "\n",
    "        individual_turbine_alarm[i+1] = individual_turbine_alarm[i+1].reset_index(drop=True)\n",
    "    return individual_turbine_alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_dict = split_errors_on_wt(df_log)\n",
    "\n",
    "# List with 25 elements containing the dataframe of each of the 25 wind turbines at Bessaker\n",
    "error_list = [*error_dict.values()]\n",
    "len(error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hS0kMDXkfWZ0"
   },
   "source": [
    "### Removing errors older than \"25-10-2017 13:20:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ihQ--WyUeSHU",
    "outputId": "a40f58c2-d507-46cc-b13d-5bc27694884a"
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "for error_df in error_list:\n",
    "    error_df[\"Start\"] = pd.to_datetime(error_df['Start'])\n",
    "    error_df.head()\n",
    "    error_df = error_df[(error_df.Start >= date(2017, 10, 25))]\n",
    "\n",
    "error_list[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ITlozXDaGfb"
   },
   "source": [
    "### Formatting the dates in the error data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vQ4l7hoNVflz"
   },
   "outputs": [],
   "source": [
    "# What I have: format='%Y-%m-%d %H:%M:%S').\n",
    "# What I want: '%d-%m-%Y %H:%M:%S'\n",
    "\n",
    "def format_dates(dataframe):\n",
    "    dataframe['Start'] = pd.to_datetime(dataframe['Start'], format='%Y-%m-%d %H:%M:%S').dt.strftime('%d-%m-%Y %H:%M:%S')\n",
    "    dataframe['End'] = pd.to_datetime(dataframe['End'], format='%Y-%m-%d %H:%M:%S').dt.strftime('%d-%m-%Y %H:%M:%S')\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "1pmsgjQh4KNB",
    "outputId": "b598e94e-7447-423f-eafe-cf9c914a8f4d"
   },
   "outputs": [],
   "source": [
    "wt = 0\n",
    "for error_df in error_list:\n",
    "    error_df = format_dates(error_df)\n",
    "    wt += 1\n",
    "error_list[3].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ng1Qo4OGf11n"
   },
   "source": [
    "### Filtering the wanted errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGC8mGGn1C4i"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Error descriptions:\n",
    "\n",
    "    \"Status_9_Substatus_8\" = Generator heating - (Manual)\n",
    "    \"Status_62_Substatus_7\" = Feeding fault - (Diff. P-set/P-actual)\n",
    "    \"Status_15_Substatus_1\" = Turbine moist - (Turbine moist Inverter 1)\n",
    "    \"Status_62_Substatus_30\" = Feeding fault - (Feeding safety circuit faulty)\n",
    " \n",
    "    '''\n",
    "selected_errors = [\n",
    "    \"Status_9_Substatus_8\",\n",
    "    \"Status_62_Substatus_7\",\n",
    "    \"Status_62_Substatus_30\"\n",
    "]\n",
    "\n",
    "def remove_unnecessary_faults(dataframe):\n",
    "    new_df = pd.DataFrame(columns=dataframe.columns)\n",
    "\n",
    "    for fault in selected_errors:\n",
    "        new_df = new_df.append(dataframe[ dataframe[\"Alarm\"] == fault])\n",
    "    return new_df\n",
    "\n",
    "j = 0\n",
    "for error_df in error_list:\n",
    "    error_df = remove_unnecessary_faults(error_df)\n",
    "    error_df.sort_values(by=['Start'], inplace = True)\n",
    "    error_df.reset_index(drop=True)\n",
    "    error_list[j] = error_df\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the frequency of the chosen faults for Bessaker WT 1-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty dataframe\n",
    "import numpy as np\n",
    "plot_df = pd.DataFrame(np.zeros((25, len(selected_errors))),columns = selected_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filling in the count for the faults for every of the 25 WT\n",
    "index = 0\n",
    "for error_df in error_list:\n",
    "    ser = error_df[\"Alarm\"].value_counts()\n",
    "    for i in range(len(ser.index)):\n",
    "        col = ser.index[i]\n",
    "        plot_df.at[index,col] = ser.values[i]\n",
    "    index += 1\n",
    "    \n",
    "plot_df.astype(int)\n",
    "\n",
    "# plotting \n",
    "fig, ax = plt.subplots(1, 1, figsize=(14,6))\n",
    "ax.set_xlabel(\"Bessaker Wind Turine number\",fontsize=20)\n",
    "ax.set_ylabel(\"Frequency of faults\",fontsize=20)\n",
    "\n",
    "plt.tick_params(axis='y')\n",
    "plot_df.plot.bar(ax=ax,width=0.5,stacked = True,fontsize = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rounding the error log timestamps to match with the SCADA time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "whbvY3NY7Szb",
    "outputId": "af1b9c54-cf92-467c-d057-a82b9fa28968"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def ceil_dt(dt, delta):\n",
    "    return dt + (datetime.min - dt) % delta\n",
    "\n",
    "def floor_dt(dt):\n",
    "    return dt.replace(second = 0)\n",
    "\n",
    "\n",
    "# For flooring starting times for an error\n",
    "def floor_timestamp_start(timestamp_error_start):\n",
    "    timestamp_error_start = datetime.strptime(timestamp_error_start,'%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "    # print(\"timestamp_error:\", timestamp_error_start)\n",
    "    \n",
    "    timestamp_error_start = floor_dt(timestamp_error_start)\n",
    "    return timestamp_error_start\n",
    "    \n",
    "# For ceiling ending times for an error UP\n",
    "def ceil_timestamp_end(timestamp_error_end):\n",
    "    timestamp_error_end = datetime.strptime(timestamp_error_end,'%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "    # print(\"timestamp_error:\", timestamp_error_end)\n",
    "\n",
    "    timestamp_error_end = ceil_dt(timestamp_error_end,timedelta(seconds = 30))\n",
    "    return timestamp_error_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = error_list[0]['Start'].iloc[24]\n",
    "end_time = error_list[0]['End'].iloc[24]\n",
    "print(start_time)\n",
    "print(end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_timestamp_start(start_time)\n",
    "print(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ceil = ceil_timestamp_end(end_time)\n",
    "print(ceil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round the errors times in error_list:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for error_df in error_list:\n",
    "    error_df['Start'] = error_df['Start'].apply(lambda x:floor_timestamp_start(x))\n",
    "    error_df['End'] = error_df['End'].apply(lambda x: ceil_timestamp_end(x))\n",
    "\n",
    "    error_df['Start'] = pd.to_datetime(error_df['Start'], format='%d-%m-%Y %H:%M:%S').dt.strftime('%d-%m-%Y %H:%M:%S')\n",
    "    error_df['End'] = pd.to_datetime(error_df['End'], format='%d-%m-%Y %H:%M:%S').dt.strftime('%d-%m-%Y %H:%M:%S')\n",
    "error_list[24].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k52TvZ3a9lv1"
   },
   "source": [
    "### Inserting new column with \"Other\" as value in SCADA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "8SAvwrx970Iy",
    "outputId": "f3aea627-a216-4a65-9185-5f7fe7ffc148"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for dataframe in list_of_wt_scada_data:\n",
    "    dataframe['Status'] = \"Other\"\n",
    "    list_of_wt_scada_data[i] = dataframe\n",
    "list_of_wt_scada_data[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_microseconds(dt):\n",
    "    return dt.replace(microsecond=0)\n",
    "\n",
    "\n",
    "df_scada = list_of_wt_scada_data[0]\n",
    "\n",
    "df_log = error_list[0]\n",
    "start = df_log.iloc[0][\"Start\"]\n",
    "print(start)\n",
    "\n",
    "df_scada['TimeStamp'] = pd.to_datetime(df_scada['TimeStamp'])\n",
    "# dataframe['TimeStamp'] = dataframe['TimeStamp'].apply(lambda x: remove_microseconds(x)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Should not cause an error:\n",
    "start_index_for_error_in_SCADA = df_scada.index[df_scada['TimeStamp'] == start].tolist()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "df_scada = list_of_wt_scada_data[0]\n",
    "df_scada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alarm list for WT01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list[0][\"Alarm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in labels from the error data to the SCADA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dv8jj4_79j3K"
   },
   "outputs": [],
   "source": [
    "def fill_in_labels_in_SCADA(df_scada, df_error_log):\n",
    "    # Looping through the errors in the error_log\n",
    "    for j in range(df_error_log.shape[0]):\n",
    "        \n",
    "        # The error information:\n",
    "        start = df_error_log.iloc[j][\"Start\"]\n",
    "        end = df_error_log.iloc[j][\"End\"]\n",
    "        label = df_error_log.iloc[j][\"Alarm\"]\n",
    "        print(label)\n",
    "        \n",
    "        try: \n",
    "            start_index_for_error_in_SCADA = df_scada.index[df_scada['TimeStamp'] == start].tolist()[0]\n",
    "            end_index_for_error_in_SCADA = df_scada.index[df_scada['TimeStamp'] == end].tolist()[0]\n",
    "\n",
    "            count = 0\n",
    "            # Filling in labels for data points in range\n",
    "            for i in range(start_index_for_error_in_SCADA, end_index_for_error_in_SCADA + 1 ):\n",
    "                count +=1\n",
    "                df_scada.at[i,'Status'] = label\n",
    "            print(\"Number of datapoints changed in the SCADA data: \", count)\n",
    "        except:\n",
    "            print(\"the\", start, \"for\", label, \"was too early for the SCADA data\")\n",
    "    return df_scada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in all labels in the SCADA data:\n",
    "wt_index = 0\n",
    "for dataframe in list_of_wt_scada_data:\n",
    "    df_log = error_list[wt_index]\n",
    "    dataframe = fill_in_labels_in_SCADA(dataframe, df_log)\n",
    "    wt_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in list_of_wt_scada_data:\n",
    "    print(dataframe.columns[1].split('-')[1],\"Unique Errors : \", dataframe['Status'].unique())\n",
    "    print(\"::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting all the dataframes with the SCADA data and the error labels together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = pd.DataFrame(columns = list_of_wt_scada_data[0].columns)\n",
    "for dataframe in list_of_wt_scada_data:\n",
    "    merged_dataset.append(dataframe, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_balance(dataframe,column,xlabel,ylabel):\n",
    "    s = dataframe[column].value_counts()\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Remove the plot frame lines. They are unnecessary chartjunk.  \n",
    "    ax = plt.subplot(111)  \n",
    "    ax.spines[\"top\"].set_visible(False)  \n",
    "    ax.spines[\"right\"].set_visible(False)  \n",
    "\n",
    "    ax.get_xaxis().tick_bottom()  \n",
    "    ax.get_yaxis().tick_left()  \n",
    "\n",
    "    # Make sure your axis ticks are large enough to be easily read.  \n",
    "    # You don't want your viewers squinting to read your plot.  \n",
    "    plt.xticks(fontsize=14)  \n",
    "    plt.yticks(fontsize=14)  \n",
    "\n",
    "    plt.ylabel(\"Frequency of fault\", fontsize=14)  \n",
    "    plt.xlabel(\"Fault type\", fontsize=14)  \n",
    "\n",
    "    dataframe[column].value_counts().plot(ax=ax, kind='bar')\n",
    "    plt.figure(figsize=(12, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in list_of_wt_scada_data:\n",
    "    print(dataframe['Status'].value_counts())\n",
    "    plot_balance(dataframe,'Status',\"Frequency of fault\",\"Fault type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# list_of_wt_scada_data[0].columns[1] = BESS-WTG01-WindVane (Average)\n",
    "def split_data(dataframe):\n",
    "    x = dataframe.loc[:,dataframe.columns[1]:dataframe.columns[34]]\n",
    "    y = dataframe[dataframe.columns[(dataframe.columns).shape[0]-1]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        x, \n",
    "        y, test_size=0.33, random_state=42,\n",
    "        stratify = y\n",
    "    )\n",
    "    return x, y, X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "x, y, X_train, X_test, y_train, y_test = split_data(list_of_wt_scada_data[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0,class_weight=\"balanced\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_train,y_train_pred))\n",
    "print(accuracy_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "print('Original dataset shape %s' % Counter(y))\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(x, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model on this resampeled dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, \n",
    "    y_res, test_size=0.33, random_state=42\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0,class_weight=\"balanced\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "labels1 = list_of_wt_scada_data[0][\"Status\"].unique().tolist()\n",
    "labelsrev = labels.reverse()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(labelsrev); ax.yaxis.set_ticklabels(labels);\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SmEsktWSZU8_"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize = (12,6))\n",
    "sns.countplot(x='TimeStamp',data = removed_columns)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmat\n",
    "\n",
    "cm = cmat.ConfusionMatrix.create(\n",
    "  # 1D arrray with ground truth labels\n",
    "  y_true = y_test,\n",
    "  # 2D array with predictions\n",
    "  y_pred = y_test_pred,\n",
    "  # (optional) List of values that might occur in y_true/y_pred\n",
    "  # labels = list_of_wt_scada_data[0][\"Status\"].unique().tolist(),\n",
    "  # (optional) List of names corresponding to labels\n",
    "  #names = list_of_wt_scada_data[0][\"Status\"].unique().tolist()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.normalize(\"recall\").plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.normalize(\"precision\").plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.normalize(\"f1score\").plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Av de vi predicted stus_62 på var 0.000256 riktig => Mange falske alarmer\n",
    "# optuna\n",
    "# sklearn gridsearch"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "fill_in_blanks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
