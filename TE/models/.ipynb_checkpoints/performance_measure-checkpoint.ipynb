{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_to_latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_measures(y_true, y_pred):\n",
    "    label_list = unique_labels(y_true)\n",
    "    acc        = accuracy_score(y_true, y_pred)\n",
    "    precision  = precision_score(y_true, y_pred, average=None, labels=label_list)\n",
    "    recall     = recall_score(y_true, y_pred, average=None, labels=label_list)\n",
    "    f1         = f1_score(y_true, y_pred, average=None, labels=label_list)\n",
    "    print('Label_list', label_list )\n",
    "    print(f'Total Accuracy \\t\\t{acc:.3f}\\n')\n",
    "    print('Status \\t\\t\\t\\t Precision \\t Recall \\t F1')\n",
    "    print('----------------------------------------------------------------------')\n",
    "    for i in range(len(label_list)):\n",
    "        print(f'{label_list[i]:<25} \\t {precision[i]:.3f} \\t\\t {recall[i]:.3f} \\t\\t {f1[i]:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    classes = unique_labels(y_true)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from sklearn import metrics\n",
    "from multiscorer import MultiScorer\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score          # Scikit's libraries for demonstration\n",
    "\n",
    "def get_cross_validation_df_OLD(clf,X,y):\n",
    "    scorer = MultiScorer({                                               # Create a MultiScorer instance\n",
    "        'precision': (precision_score, {'average': None}),\n",
    "        'recall' : (recall_score, {'average': None}),\n",
    "        'f1-score': (f1_score, {'average': None})\n",
    "    })\n",
    "\n",
    "    scores = cross_val_score(clf, X, y, scoring=scorer,cv=10)\n",
    "    \n",
    "    results = scorer.get_results()\n",
    "    \n",
    "    return_df = pd.DataFrame(columns = results.keys())\n",
    "        \n",
    "    return_df.style.hide_index()\n",
    "\n",
    "    i=0\n",
    "    for name in results.keys():\n",
    "        return_df.at[0,name] = np.average(results[name])\n",
    "        i = i+1\n",
    "        \n",
    "    pandas_to_latex.df_to_latex(return_df)\n",
    "    \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "def split_data(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=12)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the random forest model.\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "def train_rf_model(X_train,y_train, X_test):\n",
    "    # Random forest model\n",
    "    rf = RandomForestClassifier(n_estimators=10, random_state=12)\n",
    "\n",
    "    # Fitting the model\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting values\n",
    "    y_train_pred = rf.predict(X_train)\n",
    "    y_test_pred = rf.predict(X_test)\n",
    "\n",
    "    return rf, y_train_pred, y_test_pred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.640000</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.680000</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.320000</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.39</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.6</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.06</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.61</td>\n",
       "      <td>17.6</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.050000</td>\n",
       "      <td>1.06</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.83</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.17</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1045.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.86</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7.220000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1045.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.10</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.30</td>\n",
       "      <td>18.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.38</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.12</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.32</td>\n",
       "      <td>16.8</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.57</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.41</td>\n",
       "      <td>16.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.81</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>1.15</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.39</td>\n",
       "      <td>11.4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.38</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.96</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.63</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.70</td>\n",
       "      <td>17.2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.46</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.30</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.72</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.83</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.62</td>\n",
       "      <td>20.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.72</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.19</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.48</td>\n",
       "      <td>16.5</td>\n",
       "      <td>108.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.86</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.64</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.2</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.66</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.36</td>\n",
       "      <td>845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.06</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.28</td>\n",
       "      <td>16.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.71</td>\n",
       "      <td>780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.93</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.65</td>\n",
       "      <td>18.6</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.52</td>\n",
       "      <td>770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13.71</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.69</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.11</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1035.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.85</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.52</td>\n",
       "      <td>17.8</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.930000</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.50</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.61</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.82</td>\n",
       "      <td>845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.22</td>\n",
       "      <td>25.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3.20</td>\n",
       "      <td>830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.39</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.62</td>\n",
       "      <td>16.1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.45</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13.30</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.14</td>\n",
       "      <td>17.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.950000</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13.87</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.80</td>\n",
       "      <td>19.4</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.76</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.40</td>\n",
       "      <td>915.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14.02</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.21</td>\n",
       "      <td>16.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1035.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>13.32</td>\n",
       "      <td>3.24</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.420000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.62</td>\n",
       "      <td>650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>13.08</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.33</td>\n",
       "      <td>550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>13.50</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.62</td>\n",
       "      <td>24.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.30</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>12.79</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.48</td>\n",
       "      <td>22.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.26</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.47</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>13.11</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.75</td>\n",
       "      <td>25.5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.33</td>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>13.23</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.28</td>\n",
       "      <td>18.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.87</td>\n",
       "      <td>10.520000</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.51</td>\n",
       "      <td>675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>12.58</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.40</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.55</td>\n",
       "      <td>640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>13.17</td>\n",
       "      <td>5.19</td>\n",
       "      <td>2.32</td>\n",
       "      <td>22.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.55</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.48</td>\n",
       "      <td>725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>13.84</td>\n",
       "      <td>4.12</td>\n",
       "      <td>2.38</td>\n",
       "      <td>19.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.56</td>\n",
       "      <td>9.010000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.64</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>12.45</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.64</td>\n",
       "      <td>27.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.14</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.73</td>\n",
       "      <td>880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>14.34</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.70</td>\n",
       "      <td>25.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.70</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.96</td>\n",
       "      <td>660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>13.48</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.64</td>\n",
       "      <td>22.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.29</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.78</td>\n",
       "      <td>620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>12.36</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.04</td>\n",
       "      <td>7.650000</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.58</td>\n",
       "      <td>520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>13.69</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.54</td>\n",
       "      <td>20.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>12.85</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.58</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5.580000</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.11</td>\n",
       "      <td>570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>12.96</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.35</td>\n",
       "      <td>18.5</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.75</td>\n",
       "      <td>675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>13.78</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.03</td>\n",
       "      <td>9.580000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.68</td>\n",
       "      <td>615.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>13.73</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2.26</td>\n",
       "      <td>22.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.15</td>\n",
       "      <td>6.620000</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.75</td>\n",
       "      <td>520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>13.45</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.60</td>\n",
       "      <td>23.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.46</td>\n",
       "      <td>10.680000</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.56</td>\n",
       "      <td>695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>12.82</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.30</td>\n",
       "      <td>19.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.97</td>\n",
       "      <td>10.260000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.75</td>\n",
       "      <td>685.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>13.58</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.69</td>\n",
       "      <td>24.5</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.54</td>\n",
       "      <td>8.660000</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.80</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>13.40</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.86</td>\n",
       "      <td>25.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.11</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.92</td>\n",
       "      <td>630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>12.20</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.32</td>\n",
       "      <td>19.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.73</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.83</td>\n",
       "      <td>510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>12.77</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.28</td>\n",
       "      <td>19.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.899999</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.63</td>\n",
       "      <td>470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>14.16</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.24</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.71</td>\n",
       "      <td>660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "5      14.20        1.76  2.45               15.2      112.0           3.27   \n",
       "6      14.39        1.87  2.45               14.6       96.0           2.50   \n",
       "7      14.06        2.15  2.61               17.6      121.0           2.60   \n",
       "8      14.83        1.64  2.17               14.0       97.0           2.80   \n",
       "9      13.86        1.35  2.27               16.0       98.0           2.98   \n",
       "10     14.10        2.16  2.30               18.0      105.0           2.95   \n",
       "11     14.12        1.48  2.32               16.8       95.0           2.20   \n",
       "12     13.75        1.73  2.41               16.0       89.0           2.60   \n",
       "13     14.75        1.73  2.39               11.4       91.0           3.10   \n",
       "14     14.38        1.87  2.38               12.0      102.0           3.30   \n",
       "15     13.63        1.81  2.70               17.2      112.0           2.85   \n",
       "16     14.30        1.92  2.72               20.0      120.0           2.80   \n",
       "17     13.83        1.57  2.62               20.0      115.0           2.95   \n",
       "18     14.19        1.59  2.48               16.5      108.0           3.30   \n",
       "19     13.64        3.10  2.56               15.2      116.0           2.70   \n",
       "20     14.06        1.63  2.28               16.0      126.0           3.00   \n",
       "21     12.93        3.80  2.65               18.6      102.0           2.41   \n",
       "22     13.71        1.86  2.36               16.6      101.0           2.61   \n",
       "23     12.85        1.60  2.52               17.8       95.0           2.48   \n",
       "24     13.50        1.81  2.61               20.0       96.0           2.53   \n",
       "25     13.05        2.05  3.22               25.0      124.0           2.63   \n",
       "26     13.39        1.77  2.62               16.1       93.0           2.85   \n",
       "27     13.30        1.72  2.14               17.0       94.0           2.40   \n",
       "28     13.87        1.90  2.80               19.4      107.0           2.95   \n",
       "29     14.02        1.68  2.21               16.0       96.0           2.65   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "148    13.32        3.24  2.38               21.5       92.0           1.93   \n",
       "149    13.08        3.90  2.36               21.5      113.0           1.41   \n",
       "150    13.50        3.12  2.62               24.0      123.0           1.40   \n",
       "151    12.79        2.67  2.48               22.0      112.0           1.48   \n",
       "152    13.11        1.90  2.75               25.5      116.0           2.20   \n",
       "153    13.23        3.30  2.28               18.5       98.0           1.80   \n",
       "154    12.58        1.29  2.10               20.0      103.0           1.48   \n",
       "155    13.17        5.19  2.32               22.0       93.0           1.74   \n",
       "156    13.84        4.12  2.38               19.5       89.0           1.80   \n",
       "157    12.45        3.03  2.64               27.0       97.0           1.90   \n",
       "158    14.34        1.68  2.70               25.0       98.0           2.80   \n",
       "159    13.48        1.67  2.64               22.5       89.0           2.60   \n",
       "160    12.36        3.83  2.38               21.0       88.0           2.30   \n",
       "161    13.69        3.26  2.54               20.0      107.0           1.83   \n",
       "162    12.85        3.27  2.58               22.0      106.0           1.65   \n",
       "163    12.96        3.45  2.35               18.5      106.0           1.39   \n",
       "164    13.78        2.76  2.30               22.0       90.0           1.35   \n",
       "165    13.73        4.36  2.26               22.5       88.0           1.28   \n",
       "166    13.45        3.70  2.60               23.0      111.0           1.70   \n",
       "167    12.82        3.37  2.30               19.5       88.0           1.48   \n",
       "168    13.58        2.58  2.69               24.5      105.0           1.55   \n",
       "169    13.40        4.60  2.86               25.0      112.0           1.98   \n",
       "170    12.20        3.03  2.32               19.0       96.0           1.25   \n",
       "171    12.77        2.39  2.28               19.5       86.0           1.39   \n",
       "172    14.16        2.51  2.48               20.0       91.0           1.68   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29         5.640000  1.04   \n",
       "1          2.76                  0.26             1.28         4.380000  1.05   \n",
       "2          3.24                  0.30             2.81         5.680000  1.03   \n",
       "3          3.49                  0.24             2.18         7.800000  0.86   \n",
       "4          2.69                  0.39             1.82         4.320000  1.04   \n",
       "5          3.39                  0.34             1.97         6.750000  1.05   \n",
       "6          2.52                  0.30             1.98         5.250000  1.02   \n",
       "7          2.51                  0.31             1.25         5.050000  1.06   \n",
       "8          2.98                  0.29             1.98         5.200000  1.08   \n",
       "9          3.15                  0.22             1.85         7.220000  1.01   \n",
       "10         3.32                  0.22             2.38         5.750000  1.25   \n",
       "11         2.43                  0.26             1.57         5.000000  1.17   \n",
       "12         2.76                  0.29             1.81         5.600000  1.15   \n",
       "13         3.69                  0.43             2.81         5.400000  1.25   \n",
       "14         3.64                  0.29             2.96         7.500000  1.20   \n",
       "15         2.91                  0.30             1.46         7.300000  1.28   \n",
       "16         3.14                  0.33             1.97         6.200000  1.07   \n",
       "17         3.40                  0.40             1.72         6.600000  1.13   \n",
       "18         3.93                  0.32             1.86         8.700000  1.23   \n",
       "19         3.03                  0.17             1.66         5.100000  0.96   \n",
       "20         3.17                  0.24             2.10         5.650000  1.09   \n",
       "21         2.41                  0.25             1.98         4.500000  1.03   \n",
       "22         2.88                  0.27             1.69         3.800000  1.11   \n",
       "23         2.37                  0.26             1.46         3.930000  1.09   \n",
       "24         2.61                  0.28             1.66         3.520000  1.12   \n",
       "25         2.68                  0.47             1.92         3.580000  1.13   \n",
       "26         2.94                  0.34             1.45         4.800000  0.92   \n",
       "27         2.19                  0.27             1.35         3.950000  1.02   \n",
       "28         2.97                  0.37             1.76         4.500000  1.25   \n",
       "29         2.33                  0.26             1.98         4.700000  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "148        0.76                  0.45             1.25         8.420000  0.55   \n",
       "149        1.39                  0.34             1.14         9.400000  0.57   \n",
       "150        1.57                  0.22             1.25         8.600000  0.59   \n",
       "151        1.36                  0.24             1.26        10.800000  0.48   \n",
       "152        1.28                  0.26             1.56         7.100000  0.61   \n",
       "153        0.83                  0.61             1.87        10.520000  0.56   \n",
       "154        0.58                  0.53             1.40         7.600000  0.58   \n",
       "155        0.63                  0.61             1.55         7.900000  0.60   \n",
       "156        0.83                  0.48             1.56         9.010000  0.57   \n",
       "157        0.58                  0.63             1.14         7.500000  0.67   \n",
       "158        1.31                  0.53             2.70        13.000000  0.57   \n",
       "159        1.10                  0.52             2.29        11.750000  0.57   \n",
       "160        0.92                  0.50             1.04         7.650000  0.56   \n",
       "161        0.56                  0.50             0.80         5.880000  0.96   \n",
       "162        0.60                  0.60             0.96         5.580000  0.87   \n",
       "163        0.70                  0.40             0.94         5.280000  0.68   \n",
       "164        0.68                  0.41             1.03         9.580000  0.70   \n",
       "165        0.47                  0.52             1.15         6.620000  0.78   \n",
       "166        0.92                  0.43             1.46        10.680000  0.85   \n",
       "167        0.66                  0.40             0.97        10.260000  0.72   \n",
       "168        0.84                  0.39             1.54         8.660000  0.74   \n",
       "169        0.96                  0.27             1.11         8.500000  0.67   \n",
       "170        0.49                  0.40             0.73         5.500000  0.66   \n",
       "171        0.51                  0.48             0.64         9.899999  0.57   \n",
       "172        0.70                  0.44             1.24         9.700000  0.62   \n",
       "173        0.61                  0.52             1.06         7.700000  0.64   \n",
       "174        0.75                  0.43             1.41         7.300000  0.70   \n",
       "175        0.69                  0.43             1.35        10.200000  0.59   \n",
       "176        0.68                  0.53             1.46         9.300000  0.60   \n",
       "177        0.76                  0.56             1.35         9.200000  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "5                            2.85   1450.0  \n",
       "6                            3.58   1290.0  \n",
       "7                            3.58   1295.0  \n",
       "8                            2.85   1045.0  \n",
       "9                            3.55   1045.0  \n",
       "10                           3.17   1510.0  \n",
       "11                           2.82   1280.0  \n",
       "12                           2.90   1320.0  \n",
       "13                           2.73   1150.0  \n",
       "14                           3.00   1547.0  \n",
       "15                           2.88   1310.0  \n",
       "16                           2.65   1280.0  \n",
       "17                           2.57   1130.0  \n",
       "18                           2.82   1680.0  \n",
       "19                           3.36    845.0  \n",
       "20                           3.71    780.0  \n",
       "21                           3.52    770.0  \n",
       "22                           4.00   1035.0  \n",
       "23                           3.63   1015.0  \n",
       "24                           3.82    845.0  \n",
       "25                           3.20    830.0  \n",
       "26                           3.22   1195.0  \n",
       "27                           2.77   1285.0  \n",
       "28                           3.40    915.0  \n",
       "29                           3.59   1035.0  \n",
       "..                            ...      ...  \n",
       "148                          1.62    650.0  \n",
       "149                          1.33    550.0  \n",
       "150                          1.30    500.0  \n",
       "151                          1.47    480.0  \n",
       "152                          1.33    425.0  \n",
       "153                          1.51    675.0  \n",
       "154                          1.55    640.0  \n",
       "155                          1.48    725.0  \n",
       "156                          1.64    480.0  \n",
       "157                          1.73    880.0  \n",
       "158                          1.96    660.0  \n",
       "159                          1.78    620.0  \n",
       "160                          1.58    520.0  \n",
       "161                          1.82    680.0  \n",
       "162                          2.11    570.0  \n",
       "163                          1.75    675.0  \n",
       "164                          1.68    615.0  \n",
       "165                          1.75    520.0  \n",
       "166                          1.56    695.0  \n",
       "167                          1.75    685.0  \n",
       "168                          1.80    750.0  \n",
       "169                          1.92    630.0  \n",
       "170                          1.83    510.0  \n",
       "171                          1.63    470.0  \n",
       "172                          1.71    660.0  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "\n",
    "\n",
    "X = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "y = pd.DataFrame(data.target)\n",
    "y = np.array(y)\n",
    "y = np.ravel(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(X,y)\n",
    "\n",
    "rf, y_train_pred, y_test_pred = train_rf_model(X_train, y_train, X_test)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[23  0  0]\n",
      " [ 1 17  1]\n",
      " [ 0  0 17]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12a76f6a0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy \t\t0.966\n",
      "\n",
      "Status \t\t\t\t Precision \t Recall \t F1\n",
      "----------------------------------------------------------------------\n",
      "0                         \t 0.958 \t\t 1.000 \t\t 0.979\n",
      "1                         \t 1.000 \t\t 0.895 \t\t 0.944\n",
      "2                         \t 0.944 \t\t 1.000 \t\t 0.971\n"
     ]
    }
   ],
   "source": [
    "get_performance_measures(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the random forest model.\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_rf_model(X_train,y_train):\n",
    "    # Random forest model\n",
    "    rf = RandomForestClassifier(n_estimators=10, random_state=12)\n",
    "\n",
    "    # Fitting the model\n",
    "    # rf.fit(X_train, y_train)\n",
    "    return rf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "\n",
    "\n",
    "X = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "y = pd.DataFrame(data.target)\n",
    "y = np.array(y)\n",
    "y = np.ravel(y)\n",
    "\n",
    "\n",
    "rf = train_rf_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "precision &    recall &  f1-score \\\\\n",
      "\\midrule\n",
      " 0.971825 &  0.967937 &  0.967743 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = get_cross_validation_df_OLD(rf,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smote and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE NONE: \n",
      "[1. 1. 1.]\n",
      "AVERAGE NONE: \n",
      "[0.85714286 1.         1.        ]\n",
      "AVERAGE NONE: \n",
      "[1.    0.875 1.   ]\n",
      "AVERAGE NONE: \n",
      "[1.         0.85714286 0.83333333]\n",
      "AVERAGE NONE: \n",
      "[1. 1. 1.]\n",
      "AVERAGE NONE: \n",
      "[1. 1. 1.]\n",
      "AVERAGE NONE: \n",
      "[1. 1. 1.]\n",
      "AVERAGE NONE: \n",
      "[1.    0.875 1.   ]\n",
      "AVERAGE NONE: \n",
      "[0.85714286 1.         1.        ]\n",
      "AVERAGE NONE: \n",
      "[1. 1. 1.]\n",
      "The avg accc is:  0.9663398692810456\n",
      "\n",
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "precision &    recall &    f1\\_avg \\\\\n",
      "\\midrule\n",
      " 0.971825 &  0.967937 &  0.967743 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[0.96610169 0.03389831 0.        ]\n",
      " [0.02816901 0.95774648 0.01408451]\n",
      " [0.         0.02083333 0.97916667]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12af19f98>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def cross_validate_model(clf, X, y, smote = False):\n",
    "    \n",
    "    # For the confusion matrix \n",
    "    y_pred_total = []\n",
    "    y_true_total = []\n",
    "    \n",
    "    \n",
    "    # Metrics\n",
    "    f1_score_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    accuracy_list =[]\n",
    "\n",
    "    n_splits = 10\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    # MAKE SURE THE X IS A NUMPY ARRAY\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X,y), 1):\n",
    "        X_train = X[train_index]\n",
    "        y_train = y[train_index]  # Based on your code, you might need a ravel call here, but I would look into how you're generating your y\n",
    "        X_test = X[test_index]\n",
    "        y_test = y[test_index]  # See comment on ravel and  y_train\n",
    "        \n",
    "        if (smote == True):\n",
    "            sm = SMOTE()\n",
    "            X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "                \n",
    "        model = clf  # Choose a model here\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Adding to total lists\n",
    "        y_pred_total = y_pred_total + y_pred.tolist()\n",
    "        y_true_total = y_true_total + y_test.tolist()\n",
    "        \n",
    "        # Appending to lists\n",
    "        label_list = unique_labels(y_pred)\n",
    "        print(\"AVERAGE NONE: \")\n",
    "        print(precision_score(y_test, y_pred, average=None,labels=label_list))\n",
    "        \n",
    "        recall_list.append(recall_score(y_test, y_pred, average=None,labels=label_list))\n",
    "        precision_list.append(precision_score(y_test, y_pred, average=None,labels=label_list))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred,average=None,labels=label_list))\n",
    "        accuracy_list.append(model.score(X_test, y_test))\n",
    "    \n",
    "    acc_avg = np.average(accuracy_list)\n",
    "    print(\"The avg accc is: \", acc_avg)\n",
    "    \n",
    "    \n",
    "    \n",
    "    rec_avg = np.average(recall_list)\n",
    "    \n",
    "    labels = len(label_list)\n",
    "            \n",
    "        \n",
    "    prec_avg = np.average(precision_list)\n",
    "    f1_avg = np.average(f1_score_list)\n",
    "    results = {'precision': prec_avg, 'recall': rec_avg, 'f1_avg': f1_avg}\n",
    "    \n",
    "    df = pd.DataFrame(columns = results.keys())\n",
    "    \n",
    "    i=0\n",
    "    for name in results.keys():\n",
    "        df.at[0,name] = np.average(results[name])\n",
    "        i = i+1\n",
    "        \n",
    "    pandas_to_latex.df_to_latex(df)\n",
    "    \n",
    "    return df, y_true_total, y_pred_total\n",
    "\n",
    "\n",
    "df, y_true, y_pred = cross_validate_model(rf,X,y)\n",
    "plot_confusion_matrix(y_true,y_pred,True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
