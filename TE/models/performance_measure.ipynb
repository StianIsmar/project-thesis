{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_to_latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_measures(y_true, y_pred):\n",
    "    label_list = unique_labels(y_pred)\n",
    "    acc        = accuracy_score(y_true, y_pred)\n",
    "    precision  = precision_score(y_true, y_pred, average=None, labels=label_list)\n",
    "    recall     = recall_score(y_true, y_pred, average=None, labels=label_list)\n",
    "    f1         = f1_score(y_true, y_pred, average=None, labels=label_list)\n",
    "    \n",
    "    print(f'Total Accuracy \\t\\t{acc:.3f}\\n')\n",
    "    print('Status \\t\\t\\t\\t Precision \\t Recall \\t F1')\n",
    "    print('----------------------------------------------------------------------')\n",
    "    for i in range(len(label_list)):\n",
    "        print(f'{label_list[i]:<25} \\t {precision[i]:.3f} \\t\\t {recall[i]:.3f} \\t\\t {f1[i]:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    classes = unique_labels(y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from sklearn import metrics\n",
    "from multiscorer import MultiScorer\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score          # Scikit's libraries for demonstration\n",
    "\n",
    "def get_cross_validation_df_OLD(clf,X,y):\n",
    "    scorer = MultiScorer({                                               # Create a MultiScorer instance\n",
    "        'precision': (precision_score, {'average': None}),\n",
    "        'recall' : (recall_score, {'average': None}),\n",
    "        'f1-score': (f1_score, {'average': None})\n",
    "    })\n",
    "\n",
    "    scores = cross_val_score(clf, X, y, scoring=scorer,cv=10)\n",
    "    \n",
    "    results = scorer.get_results()\n",
    "    \n",
    "    return_df = pd.DataFrame(columns = results.keys())\n",
    "        \n",
    "    return_df.style.hide_index()\n",
    "\n",
    "    i=0\n",
    "    for name in results.keys():\n",
    "        return_df.at[0,name] = np.average(results[name])\n",
    "        i = i+1\n",
    "        \n",
    "    pandas_to_latex.df_to_latex(return_df)\n",
    "    \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "def split_data(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=12)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the random forest model.\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "def train_rf_model(X_train,y_train, X_test):\n",
    "    # Random forest model\n",
    "    rf = RandomForestClassifier(n_estimators=10, random_state=12)\n",
    "\n",
    "    # Fitting the model\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting values\n",
    "    y_train_pred = rf.predict(X_train)\n",
    "    y_test_pred = rf.predict(X_test)\n",
    "\n",
    "    return rf, y_train_pred, y_test_pred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "\n",
    "\n",
    "X = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "y = pd.DataFrame(data.target)\n",
    "y = np.array(y)\n",
    "y = np.ravel(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(X,y)\n",
    "\n",
    "rf, y_train_pred, y_test_pred = train_rf_model(X_train, y_train, X_test)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_performance_measures(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the random forest model.\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_rf_model(X_train,y_train):\n",
    "    # Random forest model\n",
    "    rf = RandomForestClassifier(n_estimators=10, random_state=12)\n",
    "\n",
    "    # Fitting the model\n",
    "    # rf.fit(X_train, y_train)\n",
    "    return rf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "\n",
    "\n",
    "X = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "y = pd.DataFrame(data.target)\n",
    "y = np.array(y)\n",
    "y = np.ravel(y)\n",
    "\n",
    "\n",
    "rf = train_rf_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_cross_validation_df_OLD(rf,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smote and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg accc is:  0.9663398692810456\n",
      "\n",
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "precision &    recall &    f1\\_avg \\\\\n",
      "\\midrule\n",
      " 0.971825 &  0.967937 &  0.967743 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=12, verbose=0,\n",
      "                       warm_start=False), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=12, verbose=0,\n",
      "                       warm_start=False), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=12, verbose=0,\n",
      "                       warm_start=False), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=12, verbose=0,\n",
      "                       warm_start=False), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=12, verbose=0,\n",
      "                       warm_start=False), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=12, verbose=0,\n",
      "                       warm_start=False), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=12, verbose=0,\n",
      "                       warm_start=False), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=12, verbose=0,\n",
      "                       warm_start=False), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=12, verbose=0,\n",
      "                       warm_start=False), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=12, verbose=0,\n",
      "                       warm_start=False)]\n",
      "Normalized confusion matrix\n",
      "[[0.96610169 0.03389831 0.        ]\n",
      " [0.02816901 0.95774648 0.01408451]\n",
      " [0.         0.02083333 0.97916667]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x136aca320>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def cross_validate_model(clf, X, y, SMOTE = False):\n",
    "    \n",
    "    # For the confusion matrix \n",
    "    y_pred_total = []\n",
    "    y_true_total = []\n",
    "    \n",
    "    # Classifiers\n",
    "    clf_list= []\n",
    "    \n",
    "    # Metrics\n",
    "    f1_score_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    accuracy_list =[]\n",
    "\n",
    "    n_splits = 10\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    # MAKE SURE THE X IS A NUMPY ARRAY\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X,y), 1):\n",
    "        X_train = X[train_index]\n",
    "        y_train = y[train_index]  # Based on your code, you might need a ravel call here, but I would look into how you're generating your y\n",
    "        X_test = X[test_index]\n",
    "        y_test = y[test_index]  # See comment on ravel and  y_train\n",
    "        \n",
    "        if (SMOTE == True):\n",
    "            sm = SMOTE()\n",
    "            X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "                \n",
    "        model = clf  # Choose a model here\n",
    "        model.fit(X_train, y_train)\n",
    "        clf_list.append(model)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Adding to total lists\n",
    "        y_pred_total = y_pred_total + y_pred.tolist()\n",
    "        y_true_total = y_true_total + y_test.tolist()\n",
    "\n",
    "        #y_pred_total = y_pred_total + y_pred\n",
    "        #y_true_total= y_true_total + y_test\n",
    "        \n",
    "        # Appending to lists\n",
    "        recall_list.append(recall_score(y_test, y_pred, average=None))\n",
    "        precision_list.append(precision_score(y_test, y_pred, average=None))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred,average=None))\n",
    "        accuracy_list.append(model.score(X_test, y_test))\n",
    "    \n",
    "    acc_avg = np.average(accuracy_list)\n",
    "    print(\"The avg accc is: \", acc_avg)\n",
    "    rec_avg = np.average(recall_list)\n",
    "    prec_avg = np.average(precision_list)\n",
    "    f1_avg = np.average(f1_score_list)\n",
    "    \n",
    "    results = {'precision': prec_avg, 'recall': rec_avg, 'f1_avg': f1_avg}\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(columns = results.keys())\n",
    "    \n",
    "    i=0\n",
    "    for name in results.keys():\n",
    "        df.at[0,name] = np.average(results[name])\n",
    "        i = i+1\n",
    "        \n",
    "    pandas_to_latex.df_to_latex(df)\n",
    "    \n",
    "    return df, y_true_total, y_pred_total, clf_list\n",
    "\n",
    "\n",
    "df, y_true, y_pred, clf_list = cross_validate_model(rf,X,y)\n",
    "plot_confusion_matrix(y_true,y_pred,True)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
